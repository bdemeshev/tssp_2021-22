\documentclass[12pt]{article}

\usepackage{physics}


\usepackage{tikz} % картинки в tikz
\usepackage{microtype} % свешивание пунктуации

\usepackage{array} % для столбцов фиксированной ширины

\usepackage{indentfirst} % отступ в первом параграфе

\usepackage{sectsty} % для центрирования названий частей
\allsectionsfont{\centering}

\usepackage{amsmath, amsfonts, amssymb} % куча стандартных математических плюшек

\usepackage{comment}

\usepackage[top=2cm, left=1.2cm, right=1.2cm, bottom=2cm]{geometry} % размер текста на странице

\usepackage{lastpage} % чтобы узнать номер последней страницы

\usepackage{enumitem} % дополнительные плюшки для списков
%  например \begin{enumerate}[resume] позволяет продолжить нумерацию в новом списке
\usepackage{caption}

\usepackage{url} % to use \url{link to web}

\usepackage{fancyhdr} % весёлые колонтитулы
\pagestyle{fancy}
\lhead{Time Series and Stochastic Processes}
\chead{}
\rhead{HA}
\lfoot{2021-2022}
\cfoot{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}



\usepackage{todonotes} % для вставки в документ заметок о том, что осталось сделать
% \todo{Здесь надо коэффициенты исправить}
% \missingfigure{Здесь будет Последний день Помпеи}
% \listoftodos - печатает все поставленные \todo'шки


% более красивые таблицы
\usepackage{booktabs}
% заповеди из докупентации:
% 1. Не используйте вертикальные линни
% 2. Не используйте двойные линии
% 3. Единицы измерения - в шапку таблицы
% 4. Не сокращайте .1 вместо 0.1
% 5. Повторяющееся значение повторяйте, а не говорите "то же"



\usepackage{fontspec}
\usepackage{polyglossia}

\setmainlanguage{english}
\setotherlanguages{english}

% download "Linux Libertine" fonts:
% http://www.linuxlibertine.org/index.php?id=91&L=1
\setmainfont{Linux Libertine O} % or Helvetica, Arial, Cambria
% why do we need \newfontfamily:
% http://tex.stackexchange.com/questions/91507/
\newfontfamily{\cyrillicfonttt}{Linux Libertine O}

%\AddEnumerateCounter{\asbuk}{\russian@alph}{щ} % для списков с русскими буквами
%\setlist[enumerate, 2]{label=\asbuk*),ref=\asbuk*}

%% эконометрические сокращения
\DeclareMathOperator{\Cov}{\mathbb{C}ov}
\DeclareMathOperator{\Corr}{\mathbb{C}orr}
\DeclareMathOperator{\Var}{\mathbb{V}ar}

\let\P\relax
\DeclareMathOperator{\P}{\mathbb{P}}

\DeclareMathOperator{\E}{\mathbb{E}}
% \DeclareMathOperator{\tr}{trace}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\pCorr}{\mathrm{p}\mathbb{C}\mathrm{orr}}


\newcommand \hb{\hat{\beta}}
\newcommand \hs{\hat{\sigma}}
\newcommand \htheta{\hat{\theta}}
\newcommand \s{\sigma}
\newcommand \hy{\hat{y}}
\newcommand \hY{\hat{Y}}
\newcommand \e{\varepsilon}
\newcommand \he{\hat{\e}}
\newcommand \z{z}
\newcommand \hVar{\widehat{\Var}}
\newcommand \hCorr{\widehat{\Corr}}
\newcommand \hCov{\widehat{\Cov}}
\newcommand \cN{\mathcal{N}}
\newcommand \RR{\mathbb{R}}
\newcommand \NN{\mathbb{N}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cH}{\mathcal{H}}


\begin{document}

\section*{Home Assignment 1}
\begin{enumerate}

  \item Consider the Markov chain with the transition matrix:
  
  \[
    \begin{pmatrix}
      0.2   & 0.1 & 0.7 &   0 &   0 &   0 &   0  &  0 \\
      0.4 & 0.6 & 0   &   0 &   0 &   0 &   0  &  0 \\
      0   & 0   & 0   &   0.3 &   0 &   0 &   0  &  0.7 \\
      0   & 0 & 0.3 &   0 &   0.7 &   0 &   0  &  0 \\
      0   & 0 & 0 &   0 &   0 &   1 &   0  &  0 \\
      0   & 0 & 0 &   0 &   0 &   0 &   1  &  0 \\
      0   & 0 & 0 &   0 &   0 &   0.4 &   0  &  0.6 \\
      0   & 0 & 0 &   0 &   0 &   1 &   0  &  0 \\
    \end{pmatrix}  
  \]
  
  
  \begin{enumerate}
    \item Draw the most beautiful graph for this chain. A fox or a cat is ok :)
    \item Split the chain into classes and classify them as closed and not closed.
    \item Classify the states as recurrent and transient.
  \end{enumerate}
  
  \item The Lonely Queen is standing on the A1 field of the chessboard. 
  She starts moving randomly according to chess rules. 

  \begin{enumerate}
    \item How many moves on average will it take to go back to A1?
    \item What proportion of her eternal life will the Queen spend on every field?
  \end{enumerate}

  \item Joe Biden throws a die until six appears or until he says «Stop».
  The payoff is equal to the previous thrown number before the last throw. 
  If six appears on the first throw Joe receives nothing.
  Joe maximizes the expected payoff. 

  What is the best strategy and the corresponding expected payoff?

\item Ilya Muromets stands before the first stone. There are three roads behind the stone. 
And every road ends with a new stone. And there are three new roads behind every new stone. And so on. 
Every road is guarded with one-third probability by a three headed dragon Zmei Gorynich.
Yes, there are infinitely many Zmeis Gorynichs.

\begin{enumerate}
\item What is the probability that Ilya will never meet Zmei Gorynich if Ilya chooses a road at random?
\item What is the probability that \textbf{there is} at least one Eternal Peaceful Journey without Zmei Gorynich?
\end{enumerate}

\item Ilya and Zmei finally met and play with a coin. 
They throw a coin until the sequence HTH or TTH apears. 
Ilya wins if HTH appears and Zmei wins if TTH appears.

\begin{enumerate}
  \item What is the probability that Ilya wins?
  \item What is the expected number of throws?
  \item What is the expected number of throws given that Ilya won?
\end{enumerate}

\end{enumerate}

Deadline: \textbf{2021-10-06, 21:00}. 


\section*{Home Assignment 2}


\begin{enumerate}
  \item I walk in the street during the first snow. Snowflakes falling into my palm 
  is a Poisson process with rate $\lambda = 10$ snowflakes per minute.

  \begin{enumerate}
    \item What is the probability that there will be exactly 4 snowflakes in 30 seconds?
    \item What is the expected value and variance of snowflakes in 2 minutes?
  \end{enumerate}

  \item Grasshoppers are scattered accross a field according to a Poisson process with rate one grasshopper per two square meters. 
  
  Which area should I search to find at least one grasshopper with probability $0.9$?

  \item Ilon Mask has two mobile phones. The calls to the first phone are a Poisson process 
  with rate $\lambda_1$, the calls to the second one — a Poisson process with rate $\lambda_2$. 
  Rate is measured in calls per hour. 
  These processes are independent.

  Ilon turns on the phones simulteneously. 
  
  \begin{enumerate}
    \item What is the probability that he receives exactly 2 calls on the first phone and exactly 
    3 calls on the second in one hour? Ilon Mask is like Bruce Willis and can answer unlimited 
    number of calls simulteneously. 
    \item What is covariance between the total number of calls in the first hour and the total 
    number of calls in the first two hours?
    \item (harder) What is the probability that the first phone will ring first?
  \end{enumerate}
  
  Hint: there are at least two ways to solve the hard point. 
  You can calculate a double integral 
  for exponentially distributed waiting times. 
  You can use the assumptions of Poisson process and first step approach.

  \item I wait on the bus stop. The buses arrive according a Poisson process with rate 2 per hour. 
  The taxis arrive according to a Poisson process with rate 5 per hour.  
  
  \begin{enumerate}
    \item What is the probability that at least two taxis will arrive before a bus?
    \item What is the probability that exactly two taxis will arrive before a bus?
  \end{enumerate}
  
  Hint: in this problem you may use the following fact without a proof. For two independent exponentially 
  distributed variables with rates $\lambda_1$ and $\lambda_2$: $\P(Y_1 < Y_2) = \lambda_1 / (\lambda_1 + \lambda_2)$.

  \item (harder) Students arrive to the Grusha caffé according to a Poisson process with rate $\lambda$.
  The service time are independent and exponentially distributed with rate $\mu > \lambda$.

  Let's denote by $S_t$ the number of students in the queue at time $t$ (counting the student who is serviced).
  Imagine that Grusha is open 24/24 and the arrivals and service go on and go on. 
  The distribution of $S_t$ will stabilize, you don't need to prove it. 

  Find the probability $\P(S_t = k)$ for big value of $t$. 


\end{enumerate}

Deadline: \textbf{2021-10-29, 21:00}. 


\newpage

\section*{Home Assignment 3}

\begin{enumerate}
  \item Let $\Omega = \RR$. Explicitely find the sigma-algebras $\cF_1 = \sigma(A)$, $\cF_2 = \sigma(B)$, $\cF_3 = \sigma(A, B)$ where $A=[-10;5]$ and $B=(0;10)$.
  \item I throw a die once. Let $X$ be the result of the toss. 
  Count the number of events in sigma-algebras $\cF_1 =\sigma (X)$, $\cF_2 = \sigma (\{X>3\})$, $\cF_3 = \sigma (\{X > 3\}, \{X<5\})$.

  \item Let $\Omega = \RR$. The sigma-algebra $\cF$ is generated by all the sets of the form $(-\infty, t]$,
  \[
  \cF = \sigma \left( \{ (-\infty; t] \mid t \in \RR\} \right)  
  \]
  Check whether $A_1 = (0; 10) \in \cF$, $A_2 = \{5\} \in \cF$, $A_3 = \NN \in \cF$. 

  \item Prove the following statements or provide a counter-example:
  \begin{enumerate}
    \item If $\cF_1$ and $\cF_2$ are sigma-algebras then $\cF = \cF_1 \cup \cF_2$ is sigma-algebra.
    \item If $X$ and $Y$ are independent random variables then $\card \sigma(X, Y) = \card \sigma(X) + \card \sigma(Y)$.
  \end{enumerate}

  For finite sets $\card$ denotes just the number of elements.

  \item I throw a die infinite number of times. 
  Let the random variable $X_n$ be equal to $1$ if the $n$-th toss is head and $0$ otherwise. 
  Consider a pack of sigma-algebras: $\cF_n = \sigma (X_1, \ldots, X_n)$ and $\cH_n = \sigma (X_n, X_{n+1}, X_{n+2}\, \ldots)$.

  Where possible provide and example of a non-trivial event (neither $\Omega$ nor $\emptyset$) such that 
  \begin{enumerate}
    \item $A_1 \in \cF_{2020}$;
    \item $A_2 \in \cH_{2020}$;
    \item $A_3 \in \cF_{2020}$ and $A_3 \in \cH_{2020}$;
    \item $A_4 \in \cF_n$ for all $n$; 
    \item $A_5 \in \cH_n$ for all $n$.
  \end{enumerate}

\end{enumerate}


Deadline: \textbf{2021-11-08, 21:00}. 


\end{document}



\newpage

\section*{Home Assignment 4}

\begin{enumerate}
  \item Consider three classes of random processes in discrete time:
  \begin{itemize}
    \item Markov chains, $\P(X_{n+1} = k \mid X_{n}, X_{n-1}, \ldots, X_1) = \P(X_{n+1} = k \mid X_{n})$ for all $n$.
    \item Martingales, $\E(X_{n+1} \mid X_{n}, X_{n-1}, \ldots, X_1 ) = X_n$ for all $n$.
    \item Stationary processes, $\E(X_n) = \mu$, $\Cov(X_n, X_{n-k}) = \gamma_k$ for all $n$ and $k$.
  \end{itemize}

  Provide an example of prove that the case is impossible.
  \begin{enumerate}
    \item The process $X_t$ is a Markov chain but not a martingale.
    \item The process $X_t$ is a martingale but not stationary.
    \item The process $X_t$ is a stationary martingale but not a Markov chain.
  \end{enumerate}

  \item Consider the Hedgehog problem from the exam. 
  The Hedgehog starts at the state one and moves randomly between states with transition matrix
  \[
    P = \begin{pmatrix}
      0.2 & 0.2 & 0 & 0.6 \\
      0.3 & 0.3 & 0.4 & 0 \\
      0 & 0 & 0.1 & 0.9 \\
      0 & 0 & 0.8 & 0.2 \\
    \end{pmatrix}.
  \]

  Let $p_1(t)$, $p_2(t)$, $p_3(t)$ and $p_4(t)$ be the probabilities of 
  observing the Hedgehog in each of the four states after exactly $t$ moves. 

  \begin{enumerate}
    \item Draw these probabilities as the functions of $t$ using any open source software (Python, R, Julia, \ldots).
    Provide your code.  
    \item Is the number of steps equal to $10^{2021}$ sufficient for convergence?
  \end{enumerate}
  
  \item Let $X_t$ be the Poisson process with rate $\lambda = 42$. 
  \begin{enumerate}
    \item Find a constant $\alpha$ such that $A_t = X_t - \alpha t$ is a martingale.
    \item Find a constant $\beta$ such that $B_t = \exp(X_t - \beta t)$ is a martingale.
  \end{enumerate}


\end{enumerate}


Deadline: \textbf{2021-11-08, 21:00}. 





\newpage




Deadline: 9 October 2020, 21:00 MSK.


\newpage
\lfoot{Publication: 2020-11-04, 21:40:00}
\rfoot{\url{https://forms.gle/LivmsZfFmgSuB6eY6}}
\section*{Home Assignment 3}
\begin{enumerate}
  \item Consider the Vasicek interest rate model, 
  \[
    dR_t=a(b-R_t) \, dt+\sigma \, dW_t.
  \]
  Here $R_t$ is the interest rate and $a$, $b$ and $\sigma$ are positive constants.
  \begin{enumerate}
  \item Using the substitution $Y_t=e^{at} R_t$ find the solution of the stochastic differential equation;
  \item Find $\E(R_t)$ and $\Var(R_t)$.
  \item Which value in this model would you call long-term equilibrium rate and why?
  \end{enumerate}

  \item Let $X_t$ be the exchange rate measured in roubles per dollar. 
  We suppose that $dX_t = \mu X_t dt + \sigma X_t dW_t$. 
  
  Consider the inverse exchange rate $Y_t = 1/X_t$ measured in dollars per rouble. 
  
  Write the stochastic differential equation for $dY_t$. 
  The equation may contain $Y_t$ and constants, but not $X_t$.

  \item Let $W_t^a$ and $W_t^b$ be two independent Wiener processes.
  Consider the process $Q_t = \alpha W_t^a + \beta W_t^b$, where $\alpha^2 + \beta^2 = 1$.

  \begin{enumerate}
    \item Is $Q_t$ a Wiener process? Carefully check all the assumptions. 
  \item Find the limit in $L^2$ for $n\to\infty$ of 
\[
A_n = \sum_{i=1}^{n} \left(W^a(it/n) - W^a((i-1)t/n)\right)\left(W^b(it/n) - W^b((i-1)t/n)\right) 
\]

\item Find the limit in $L^2$ for $n\to\infty$ of
\[
B_n = \sum_{i=1}^{n} \left(Q(it/n) - Q((i-1)t/n)\right)\left(W^b(it/n) - W^b((i-1)t/n)\right) 
\]
\item Find $\Corr(Q_t, W_t^b)$.

\item Without formal proof guess the value of $dQ_t dW_b^t$ in the Ito's lemma for correlated Wiener processes.
\end{enumerate}

\item Consider the Cox-Ingersoll-Ross interest rate model
\[
  dR_t=a(b-R_t) \, dt+\sigma \sqrt{R_t} \, dW_t.
\]
Here $R_t$ is the interest rate and $a$, $b$ and $\sigma$ are positive constants.


Find $\E(R_t)$ and $\Var(R_t)$.


\item The share price $S_t$ satisfies the Black and Scholes model and $dX_t = t dS_t$. 

Find $\E(X_t)$ and $\Var(X_t)$.



\end{enumerate}



% Deadline: 25 September 2020, 21:00 MSK.


\newpage
\lfoot{Publication: 2020-11-21, 20:20:20}


\begin{enumerate}

\item Consider the Black and Scholes model. At time $T > 1$ the asset pays you
\[
  X_T = \begin{cases} 
    \ln S_T, \text{ if } S_T > 1; \\
    0, \text{ otherwise.}
  \end{cases}
\]

Today is $t=1$. Find the current price $X_1$ of this asset.

  \item Пусть $y_{t}$ — стационарный процесс. Проверьте стационарность процессов:
  \begin{enumerate}
  \item $a_{t}=\Delta^2 y_{t}$;
  \item $b_{t}=2y_{t}+3y_{t-1} + 18$.
  \end{enumerate}

\item  Правильный кубик подбрасывают три раза, обозначим результаты подбрасываний $X_1$, $X_2$ и $X_3$. 
Также ввёдем обозначения для сумм $L=X_1+X_2$, $R=X_2+X_3$ и $S=X_1+X_2+X_3$.
\begin{enumerate}
\item С помощью качественных рассуждений (без вычислений) определите знаки частных корреляций\footnote{Запись $\pCorr(X, Y; Z)$ означает частную корреляцию между $X$ и $Y$, «очищенных» от эффекта $Z$.}
$\pCorr(L, R; S)$,
  $\pCorr(L, S; R)$,  $\pCorr(X_1, R; S)$. 
%   Буквально одной-двумя фразами аргументируйте знак каждой частной корреляции.
  \item Найдите точное значение каждой частной корреляции.
\end{enumerate}


% \item Пусть $u_t$ — белый шум. Рассмотрим процесс $y_t=4+0.5y_{t-1}+u_t$ при $t\geq 1$ с различными начальными условиями.

% Найдите $\E(y_t)$, $\Var(y_t)$ и определите, является ли процесс стационарным, если:
% \begin{enumerate}
% \item $y_1=8+u_1$;
% \item $y_1=8+\frac{2}{\sqrt{3}}u_1$;
% \end{enumerate}

\item У эконометрессы Ефросиньи был стационарный ряд $(y_t)$, $t\geq 1$ с $\E(y_t)=5$. $\Var(y_t) = 16$ 
и $\Cov(y_t, y_{t-1})= 4$.

Ефросинье было скучно и она подбрасывала неправильную монетку, выпадающую орлом с вероятностью $0.7$. 
Если выпадал орёл, она оставляла очередной $y_t$, если решка — то зачёркивала. 

Обозначим полученную новую последовательность $(z_t)$.

\begin{enumerate}
  \item Является ли $(z_t)$ стационарным?
 \item Найдите $\E(z_t)$, $\Var(z_t)$ и $\Cov(z_t, z_{t-1})$.
\end{enumerate}

\item Рассмотрим стационарное решение $(y_t)$ уравнения $y_t = 6 + 0.5 y_{t-1} + u_t -0.3 u_{t-1}$, где $(u_t)$ — белый шум.

\begin{enumerate}
  \item Найдите $\E(y_t)$ и $\Var(y_t)$.
  \item Найдите первые три значения автокорреляционной функции.
  \item Найдите первые три значения частной автокорреляционной функции.
\end{enumerate}

Hint: для данного случая есть теорема, которая гарантирует, что у стационарного решения $\Cov(y_t, u_{t+k}) = 0$ при $k>0$.


\end{enumerate}


\newpage
\lfoot{Publication: 2020-12-15, 12:00:00}

\begin{enumerate}
  \item Consider $y_t$ described by $ETS(MNM)$ model. You can find all the equations in \url{https://otexts.com/fpp3/}.
  Is it true that $z_t = \ln y_t$ is exactly described by $ETS(ANA)$ model? Approximately?
  \item  Consider $ETS(AA_dN)$ model with $\phi = 0.9$, $\alpha=0.3$, $\beta=0.1$ and $\sigma^2=16$. 
  Express 95\% predictive intervals for $y_{t+1}$ and $y_{t+2}$ in terms of $\ell_t$, $b_t$, $y_t$ and $u_t$. 
  \item Find $\E(y_t)$, $\Var(y_t)$, $\Cov(y_t, y_{t+1})$ in the $ETS(AAN)$ model with given $\ell_0$, $b_0$, $\alpha$, $\beta$ and $\sigma^2$.
  \item Consider stationary $ARMA(1, 1)$ process, $y_t = 0.7 y_{t-1} + u_t + 0.2 u_{t-1}$, where $\Var(u_t) = 16$.
  \begin{enumerate}
    \item Find $\E(y_{t+1} \mid y_t, u_t)$ and $\Var(y_{t+1} \mid y_t, u_t)$;
    \item Find $\E(y_{t+1} \mid y_t)$ and $\Var(y_{t+1} \mid y_t)$.
  \end{enumerate}
  \item Consider the equation $y_t - 2.5 y_{t-1} + y_{t-2} = u_t$, where $u_t$ is a white noise.
  
  \begin{enumerate}
    \item Does it have any stationary solution of the form $y_t = u_t  + \alpha_{1} u_{t-1} + \alpha_{2} u_{t-2} + \ldots$?
    
    If yes then find $\alpha_1$, $\alpha_2$, $\alpha_3$.

    \item (*) Does it have any stationary solution of the form $y_t = \ldots + \alpha_{-1} u_{t+1} + \alpha_0 u_t + \alpha_{1} u_{t-1} + \ldots$?

    If yes then find $\alpha_{-1}$, $\alpha_0$, $\alpha_1$.

    Hint: $(1-2.5L + L^2) = (1 - 2L) (1 - 0.5L)$.

  \end{enumerate}
  
  
\end{enumerate}


You can find more problems in the problem book draft, \url{https://github.com/bdemeshev/ts_pset}.

\newpage
\lfoot{Publication: }

Beta distribution $Beta(a, b)$ has density function $f(x)$ proportional to $x^{a-1} (1-x)^{b-1}$ on $[0;1]$.
The proportionality constant depends on $a$ and $b$. 

Gamma distribution $Gamma(\lambda, k)$ has density function $f(x)$ proportional to $x^{k-1} \lambda^k \exp(-\lambda x)$ on $[0;+\infty)$.
The proportionality constant depends on $k$. 

You can find more information about these distributions on Wikipedia or elsewhere, I believe in you! :)



\begin{enumerate}

\item Consider a random sample $Y_1$, $Y_2$, \ldots, $Y_n$ from uniform distribution
on $[-a; 7a]$.
\begin{enumerate}
  \item Find method of moments estimator for $a$ using $\E(Y_i)$.
  \item Find method of moments estimator for $a$ using $\E(\abs{Y_i})$.
  \item Are these method of moments estimators unbiased?
  \item Which method of moments estimator has lowest mean squared error?
  \item Find the maximum likelihood estimator of $a$.
\end{enumerate}


  \item Find the moment generating function for the $Gamma(\lambda, k)$ distribution.


  \item Find sufficient statistics for unknown parameters:
  \begin{enumerate}
    \item Beta distribution $Beta(a, b)$ with unknown $a$ and $b$.
    \item Beta distribution $Beta(a, b)$ with known $a$ and unknown $b$.
    \item Gamma distribution $Gamma(\lambda, k)$ with unknown $\lambda$ and $k$.
    \item Gamma distribution $Gamma(\lambda, k)$ with known $k$ and unknown $\lambda$.
  \end{enumerate}

  \item The log-density function has the following form:
  \[
  \ln f(x \mid \theta_1, \theta_2) = a(x) - b(\theta_1, \theta_2) + \theta_1 c_1(x) + \theta_2 c_2(x),  
  \]
  where $a$, $b$, $c_1$ and $c_2$ are some known functions. 

  \begin{enumerate}
    \item Find the sufficient statistics for unknown $\theta_1$, $\theta_2$.
    \item Find the sufficient statistics for unknown $\theta_1$ with known $\theta_2$.
    \item Express $\E(c_1(X))$ using the function $b(\theta_1, \theta_2)$.
    \item Express $\Cov(c_1(X), c_2(X))$ using the function $b(\theta_1, \theta_2)$.
  \end{enumerate}

  Hint for the last two points: what are the expected value and the variance of the score-function?

  \item The estimator $\hat\theta$ is unbiased but not necessary obtained by maximum likelihood.
  
  Find $\Cov(\hat\theta, \partial \ell/\partial \theta)$ where $\ell$ is the log-likelihood function. 


\end{enumerate}




\newpage
\lfoot{Publication: }

A little bit of inequalities\ldots 

\begin{enumerate}
  \item You know that $\E((X - 20)^6) = 1000$ and $\E(X) = 20$.
  
  What are the possible values for $\P(\abs{X-20} \geq 20)$?
  
  \item The loose milk price at day $t$ is $M_t$. 
  The variables $(M_t)$ are independent and identically distributed with $\E(M_t) = 100$ 
  roubles per liter. 
  
  Every day Masha buys one liter of milk. Every day Sasha buys loose milk exactly for 100 roubles. 

  After 30 days Masha and Sasha compares their spendings. Let's denote by $X^S$ and $X^M$ the 
  total expenditures by Sasha and Masha. And let's denote by $Q^S$ and $Q^M$ the total volume
  of milk bought by Sasha and Masha. 

  \begin{enumerate}
    \item Compare $\E(X^S)$ and $\E(X^M)$.
    \item Compare $\E(Q^S)$ and $\E(Q^M)$.
  \end{enumerate}

\end{enumerate}

A little bit of estimation\ldots 

\begin{enumerate}[resume]
  \item Kazimir Malevich draws random black rectangles. One side of a rectangle, $A_i$, is approximately normally distributed $\cN(a; 1)$,
  the other side, $B_i$, is approximately $\cN(b, 1)$.
  All variables are independent. 

  \begin{enumerate}
    \item Calculate $\E(S_i)$ and $\E(S_i^2)$.
    \item You have recorded data of area for 100 paintings: $S_i$: $\bar S = 36$, $\sum S_i^2 = 162500$.
    Estimate $a$ and $b$ using method of moments.     
  \end{enumerate}

  \item In one of the offices there are 4 bank teller: Alice, Bob, Carol and Dave. 
  Service times are independent and 
  exponentially distributed with unknown rate $\lambda$. 
  Exactly at the opening time exactly 4 clients entered the office. 

  Provide maximum likelihood estimate of $\lambda$ in the following cases:
  \begin{enumerate}
    \item Alice serviced her client in 20 minutes. 
    Bob serviced his client in 15 minutes. 
    Carol and Dave forgot to note the service time. 

    \item Alice serviced her client in 15 minutes. 
    Bob serviced his client in 20 minutes. 
    Carol and Dave were servicing their first clients more than 30 minutes.
    
  % \item Alice and Bob serviced their first clients in less than 30 minutes. 
  % Carol and Dave were servicing their first clients more than 30 minutes.

  \item The first client was serviced in 15 minutes. 
  The second client was serviced in 20 minutes. 
    
  \end{enumerate}


  \item The random variables $X_1$, $X_2$, \ldots, $X_n$ are independent and binomially distributed $Bin(100, p)$.
  Researcher Neznaika tries to estimate the parameter $\theta = \P(X_i = 2)$.

  He has invented an estimator $\hat\theta = \begin{cases}
    1, \text{ if } X_1 = 2, \\
    0, \text{ otherwise.}
  \end{cases}$.

  \begin{enumerate}
    \item Find the minimal sufficient statistic for $p$, let's denote it by $T$.
    \item Using Rao-Blackwell theorem construct a better estimate $\hat\theta'$ using $T$.
    \item Check whether the new estimator is unbiased.
    \item Using delta-method estimate the variance of $\hat\theta'$ for $n=1000$ and $\sum X_i = 42000$ and 
    find 99\% confidence interval. 
  \end{enumerate}


\end{enumerate}



\end{document}

